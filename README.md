 Cricket Data Analytics: Web Scraping & Power BI ETL

Descripci贸n del Proyecto
Este proyecto demuestra una soluci贸n t茅cnica avanzada para la extracci贸n, transformaci贸n y carga (ETL) de estad铆sticas deportivas desde la web oficial de ESPN Cricinfo. El objetivo principal fue automatizar la captura de datos de bateo mediante t茅cnicas de scraping din谩mico en Power Query.

Flujo de Trabajo (Workflow)
Scraping Basado en Patrones: Se utiliz贸 la funci贸n "Extraer tabla mediante ejemplos" para identificar los selectores CSS necesarios en el HTML de origen.

Modularizaci贸n con Lenguaje M: Se convirti贸 la consulta inicial en una Funci贸n Personalizada parametrizada (ps as text). Esto permite que la URL sea din谩mica (&page=" & ps & ") para manejar la paginaci贸n del sitio.

Arquitectura de Datos Robusta: * Se cre贸 una tabla de cabeceras est谩tica comprimida en binario para asegurar la consistencia del esquema.

Se gener贸 una lista iterativa (del 1 al 3) para invocar la funci贸n sobre m煤ltiples p谩ginas de forma autom谩tica.

Pipeline de Limpieza:

Sustituci贸n de valores nulos o caracteres especiales ("-") por valores num茅ricos calculables.

Configuraci贸n de Cultura/Locale (en-US) para garantizar que promedios y porcentajes se carguen correctamente sin importar la regi贸n del sistema.

Resultado Final
Tras el proceso de limpieza, los datos quedaron estructurados de la siguiente manera:

Volumen: Tabla consolidada de 106 filas y 15 columnas t茅cnicas.

Calidad: Tipos de datos estrictos (Enteros para partidos/carreras y Decimales para promedios).

Listos para el An谩lisis: Limpieza completa de las columnas cr铆ticas: Player, Runs, Ave (Average) y SR (Strike Rate).

------------------------------------------------

Project Overview
This project showcases an advanced technical solution for ETL (Extract, Transform, Load) operations, sourcing sports statistics from the official ESPN Cricinfo website. The primary goal was to automate the capture of batting data using dynamic web scraping techniques within Power Query.

Workflow
Pattern-Based Scraping: "Extract table using examples" was utilized to identify the required CSS selectors within the source HTML.

M Language Modularization: The initial query was converted into a parameterized Custom Function (ps as text). This enables dynamic URL handling (&page=" & ps & ") to manage website pagination.

Robust Data Architecture: * A binary-compressed static header table was created to ensure schema consistency.

An iterative list (1 to 3) was generated to automatically invoke the function across multiple web pages.

Cleaning Pipeline:

Replacement of null values or special characters ("-") with calculable numeric values (0).

Culture/Locale (en-US) configuration to ensure averages and percentages load correctly regardless of the host system's regional settings.

Final Result
After the cleaning process, the data was structured as follows:

Volume: A consolidated table consisting of 106 rows and 15 technical columns.

Quality: Strict data typing (Integers for matches/runs and Decimals for averages).

Analysis-Ready: Complete sanitization of critical columns: Player, Runs, Ave (Average), and SR (Strike Rate).
